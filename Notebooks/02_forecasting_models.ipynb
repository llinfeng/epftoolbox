{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EPF Toolbox: forecasting models demo\n",
        "\n",
        "Second notebook to generate day-ahead forecasts with `epftoolbox.models`.\n",
        "- Mirrors the examples in `examples/` and the [models documentation](https://epftoolbox.readthedocs.io/en/latest/modules/models.html).\n",
        "- Reuses data cached in `datasets/` from `01_load_data.ipynb`.\n",
        "- Saves forecasts to `forecasts_local/` (created below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: /home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox\n",
            "Data path: /home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/datasets\n",
            "Experiments path: /home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/forecasts_local\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd().resolve()\n",
        "if repo_root.name == 'Notebooks':\n",
        "    repo_root = repo_root.parent\n",
        "\n",
        "data_path = repo_root / 'datasets'\n",
        "work_path = repo_root / 'forecasts_local'\n",
        "work_path.mkdir(exist_ok=True)\n",
        "\n",
        "print(f'Repo root: {repo_root}')\n",
        "print(f'Data path: {data_path}')\n",
        "print(f'Experiments path: {work_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a30b0b4",
      "metadata": {},
      "source": [
        "# Verify GPU compute\n",
        "In Temrinal, run: \n",
        "```bash\n",
        "watch -n0.2 nvidia-smi  \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7e1d66c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-01 15:40:06.936095: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-01 15:40:06.966093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-12-01 15:40:06.966138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-12-01 15:40:06.967063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-12-01 15:40:06.973520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-01 15:40:07.587674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-12-01 15:40:08.374450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.419252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.419299: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.419304: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n",
            "2025-12-01 15:40:08.421990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.422023: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.422034: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.422038: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-01 15:40:08.613743: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.613793: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.613800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-12-01 15:40:08.613826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-12-01 15:40:08.613855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5176 MB memory:  -> device: 0, name: NVIDIA RTX PRO 1000 Blackwell Generation Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "with tf.device(\"/GPU:0\"):\n",
        "     a = tf.random.normal([2000, 2000])\n",
        "     b = tf.random.normal([2000, 2000])\n",
        "     _ = tf.matmul(a, b)  # warms up JIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ada3cc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 0 took 1.078s\n",
            "iter 1 took 0.878s\n",
            "iter 2 took 0.866s\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf, time\n",
        "\n",
        "tf.debugging.set_log_device_placement(True)  # optional, see placements\n",
        "\n",
        "with tf.device(\"/GPU:0\"):\n",
        "    a = tf.random.normal([8192, 8192])\n",
        "    b = tf.random.normal([8192, 8192])\n",
        "    for i in range(3):\n",
        "        t0 = time.time()\n",
        "        c = tf.matmul(a, b)\n",
        "        _ = c.numpy()  # force materialization\n",
        "        print(f\"iter {i} took {time.time() - t0:.3f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LEAR daily recalibration (CPU extensive)\n",
        "\n",
        "Quick run of the LEAR example (`epftoolbox.models.evaluate_lear_in_test_dataset`) to produce a forecast CSV in `forecasts_local/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/hyperopt/atpe.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from epftoolbox.models import evaluate_lear_in_test_dataset\n",
        "\n",
        "dataset = 'PJM'\n",
        "years_test = 2\n",
        "calibration_window = 364 * 3\n",
        "\n",
        "forecast_lear = evaluate_lear_in_test_dataset(\n",
        "    path_datasets_folder=str(data_path),\n",
        "    path_recalibration_folder=str(work_path),\n",
        "    dataset=dataset,\n",
        "    years_test=years_test,\n",
        "    calibration_window=calibration_window,\n",
        ")\n",
        "\n",
        "forecast_lear.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DNN daily recalibration (requires hyperparameters)\n",
        "\n",
        "The DNN helpers mirror `examples/recalibrating_dnn_simplified.py`, but they need a trials file from `examples/optimizing_hyperparameters_dnn.py`.\n",
        "The cell below checks for the expected file in `forecasts_local/` and only runs when it exists.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64687eb4",
      "metadata": {},
      "source": [
        "### Optional: create DNN hyperparameter trials\n",
        "\n",
        "The DNN helper needs a trials file (hyperparameter search). If it is missing, run a small hyperopt sweep here to generate it. Increase `max_evals` for a proper search; the default keeps this demo quick.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737ef654",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running a small hyperparameter search to create trials file...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "2025-12-01 15:28:40.724507: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2025-12-01 15:28:40.729920: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 12.0\n",
            "2025-12-01 15:28:40.729951: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at /home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc/bin/ptxas\n",
            "2025-12-01 15:28:40.730019: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:42.754334: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.229913: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.230042: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.230058: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.230076: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.230427: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.231205: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.231392: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.231924: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.379505: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.379645: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.380701: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.381279: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.381342: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.381374: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.381532: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.382516: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:48.497757: I external/local_xla/xla/service/service.cc:168] XLA service 0x7058033603a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-12-01 15:28:48.497793: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX PRO 1000 Blackwell Generation Laptop GPU, Compute Capability 12.0\n",
            "2025-12-01 15:28:48.503022: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-12-01 15:28:48.519229: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2025-12-01 15:28:48.538106: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:408] Couldn't read CUDA driver version.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1764574128.549884   14868 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 1/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 4702943.6 | sMAPE: 41.72 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 11.8 | sMAPE: 41.24 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "2025-12-01 15:28:59.693611: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.769174: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.769227: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.769686: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.771010: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.771095: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.771179: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.771202: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.771764: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:28:59.895970: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.036269: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.036598: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.036713: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.036726: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.037036: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.037102: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.037589: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.038867: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.038949: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-12-01 15:29:00.369545: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 2/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 7.3 | sMAPE: 17.13 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 4.9 | sMAPE: 17.76 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "2025-12-01 15:29:52.703587: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 3/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.3 | sMAPE: 15.55 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 4.3 | sMAPE: 16.43 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 4/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "2025-12-01 15:30:51.491961: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 5/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 6/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 7/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 8/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tested 9/10 iterations.\n",
            "Best MAE - Validation Dataset\n",
            "  MAE: 6.1 | sMAPE: 13.97 %\n",
            "\n",
            "Best MAE - Test Dataset\n",
            "  MAE: 3.9 | sMAPE: 14.85 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved trials to: /home/llinfeng/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/forecasts_local/DNN_hyperparameters_nl2_datPJM_YT2_SF_CW4_1\n"
          ]
        }
      ],
      "source": [
        "from epftoolbox.models import hyperparameter_optimizer\n",
        "\n",
        "nlayers = 2\n",
        "shuffle_train = 1\n",
        "data_augmentation = 0\n",
        "calibration_window = 4\n",
        "years_test = 2\n",
        "dataset = 'PJM'\n",
        "experiment_id = 1\n",
        "begin_test_date = None\n",
        "end_test_date = None\n",
        "max_evals = 10  # increase for a full search; small for a quick demo\n",
        "\n",
        "trials_file_name = (\n",
        "    f'DNN_hyperparameters_nl{nlayers}_dat{dataset}_YT{years_test}'\n",
        "    f\"{'_SF' if shuffle_train else ''}\"\n",
        "    f\"{'_DA' if data_augmentation else ''}\"\n",
        "    f'_CW{calibration_window}_{experiment_id}'\n",
        ")\n",
        "trials_path = work_path / trials_file_name\n",
        "\n",
        "if trials_path.exists():\n",
        "    print('Trials file already exists, skipping hyperparameter search:')\n",
        "    print(trials_path)\n",
        "else:\n",
        "    print('Running a small hyperparameter search to create trials file...')\n",
        "    hyperparameter_optimizer(\n",
        "        path_datasets_folder=str(data_path),\n",
        "        path_hyperparameters_folder=str(work_path),\n",
        "        new_hyperopt=True,\n",
        "        max_evals=max_evals,\n",
        "        nlayers=nlayers,\n",
        "        dataset=dataset,\n",
        "        years_test=years_test,\n",
        "        calibration_window=calibration_window,\n",
        "        shuffle_train=bool(shuffle_train),\n",
        "        data_augmentation=bool(data_augmentation),\n",
        "        experiment_id=experiment_id,\n",
        "        begin_test_date=begin_test_date,\n",
        "        end_test_date=end_test_date,\n",
        "    )\n",
        "    print('Saved trials to:', trials_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016-12-27 - sMAPE: 3.83%  |  MAE: 0.931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016-12-28 - sMAPE: 7.29%  |  MAE: 1.889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016-12-29 - sMAPE: 8.24%  |  MAE: 2.154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016-12-30 - sMAPE: 7.17%  |  MAE: 1.916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2016-12-31 - sMAPE: 6.93%  |  MAE: 1.851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-01-01 - sMAPE: 6.54%  |  MAE: 1.754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-01-02 - sMAPE: 6.62%  |  MAE: 1.784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-01-03 - sMAPE: 7.32%  |  MAE: 1.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-01-04 - sMAPE: 7.23%  |  MAE: 1.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017-01-05 - sMAPE: 8.28%  |  MAE: 2.469\n",
            "2017-01-06 - sMAPE: 8.41%  |  MAE: 2.569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m trials_path = work_path / trials_file_name\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trials_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     forecast_dnn = \u001b[43mevaluate_dnn_in_test_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_hyperparameter_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_datasets_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_recalibration_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43myears_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43myears_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshuffle_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcalibration_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalibration_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_recalibration\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbegin_test_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbegin_test_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_test_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_test_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     display(forecast_dnn.head())\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/epftoolbox/models/_dnn.py:743\u001b[39m, in \u001b[36mevaluate_dnn_in_test_dataset\u001b[39m\u001b[34m(experiment_id, path_datasets_folder, path_hyperparameter_folder, path_recalibration_folder, nlayers, dataset, years_test, shuffle_train, data_augmentation, calibration_window, new_recalibration, begin_test_date, end_test_date)\u001b[39m\n\u001b[32m    739\u001b[39m data_available.loc[date:date + pd.Timedelta(hours=\u001b[32m23\u001b[39m), \u001b[33m'\u001b[39m\u001b[33mPrice\u001b[39m\u001b[33m'\u001b[39m] = np.nan\n\u001b[32m    741\u001b[39m \u001b[38;5;66;03m# Recalibrating the model with the most up-to-date available data and making a prediction\u001b[39;00m\n\u001b[32m    742\u001b[39m \u001b[38;5;66;03m# for the next day\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m743\u001b[39m Yp = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecalibrate_and_forecast_next_day\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_available\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_day_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[38;5;66;03m# Saving the current prediction\u001b[39;00m\n\u001b[32m    746\u001b[39m forecast.loc[date, :] = Yp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/epftoolbox/models/_dnn.py:604\u001b[39m, in \u001b[36mDNN.recalibrate_and_forecast_next_day\u001b[39m\u001b[34m(self, df, next_day_date)\u001b[39m\n\u001b[32m    600\u001b[39m Xtrain, Xval, Xtest, Ytrain, Yval = \\\n\u001b[32m    601\u001b[39m     \u001b[38;5;28mself\u001b[39m._regularize_data(Xtrain=Xtrain, Xval=Xval, Xtest=Xtest, Ytrain=Ytrain, Yval=Yval)\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# Recalibrating the neural network and extracting the prediction\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m Yp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecalibrate_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mYval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Yp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/epftoolbox/models/_dnn.py:531\u001b[39m, in \u001b[36mDNN.recalibrate_predict\u001b[39m\u001b[34m(self, Xtrain, Ytrain, Xval, Yval, Xtest)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecalibrate_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xtrain, Ytrain, Xval, Yval, Xtest):\n\u001b[32m    507\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Method that first recalibrates the DNN model and then makes a prediction.\u001b[39;00m\n\u001b[32m    508\u001b[39m \n\u001b[32m    509\u001b[39m \u001b[33;03m    The method receives the training and validation dataset, and trains a :class:`DNNModel` model\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    529\u001b[39m \u001b[33;03m        An array containing the predictions in the test dataset\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecalibrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mYval\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[32m    532\u001b[39m     Yp = \u001b[38;5;28mself\u001b[39m.predict(X=Xtest)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.clear_session()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/epftoolbox/models/_dnn.py:504\u001b[39m, in \u001b[36mDNN.recalibrate\u001b[39m\u001b[34m(self, Xtrain, Ytrain, Xval, Yval)\u001b[39m\n\u001b[32m    492\u001b[39m np.random.seed(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.best_hyperparameters[\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m.model = DNNModel(neurons=neurons, n_features=Xtrain.shape[-\u001b[32m1\u001b[39m], \n\u001b[32m    495\u001b[39m                       dropout=\u001b[38;5;28mself\u001b[39m.best_hyperparameters[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m    496\u001b[39m                       batch_normalization=\u001b[38;5;28mself\u001b[39m.best_hyperparameters[\u001b[33m'\u001b[39m\u001b[33mbatch_normalization\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m   (...)\u001b[39m\u001b[32m    501\u001b[39m                       lambda_reg=\u001b[38;5;28mself\u001b[39m.best_hyperparameters[\u001b[33m'\u001b[39m\u001b[33mlambdal1\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    502\u001b[39m                       initializer=\u001b[38;5;28mself\u001b[39m.best_hyperparameters[\u001b[33m'\u001b[39m\u001b[33minit\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYval\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/epftoolbox/models/_dnn.py:270\u001b[39m, in \u001b[36mDNNModel.fit\u001b[39m\u001b[34m(self, trainX, trainY, valX, valY)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m    268\u001b[39m     start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# Updating epoch metrics and displaying useful information\u001b[39;00m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[39m\n\u001b[32m   1799\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.profiler.experimental.Trace(\n\u001b[32m   1800\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1801\u001b[39m     epoch_num=epoch,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1804\u001b[39m     _r=\u001b[32m1\u001b[39m,\n\u001b[32m   1805\u001b[39m ):\n\u001b[32m   1806\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m-> \u001b[39m\u001b[32m1807\u001b[39m     tmp_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1808\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_handler.should_sync:\n\u001b[32m   1809\u001b[39m         context.async_wait()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    829\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    834\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    835\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    865\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    866\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m    867\u001b[39m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    872\u001b[39m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[32m    873\u001b[39m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[32m    874\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1319\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1321\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1322\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1323\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1324\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1325\u001b[39m     args,\n\u001b[32m   1326\u001b[39m     possible_gradient_type,\n\u001b[32m   1327\u001b[39m     executing_eagerly)\n\u001b[32m   1328\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:242\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != expected_len:\n\u001b[32m    235\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    236\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSignature specifies \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m arguments, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Expected inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.cached_definition.signature.input_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Received inputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Function Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.function_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mInterpolateRuntimeError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m    243\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.control_dependencies(\u001b[38;5;28mself\u001b[39m._call_options.control_captures):\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/GitRepo/1_Projects/DianLi_电力/Benchmark1-epftoolbox/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:641\u001b[39m, in \u001b[36mInterpolateRuntimeError.__init__\u001b[39m\u001b[34m(self, top_level_func)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Context Manager that interpolates exceptions received by AtomicFunction.\"\"\"\u001b[39;00m\n\u001b[32m    639\u001b[39m DENY_LIST_PHRASES = [\u001b[33m\"\u001b[39m\u001b[33m<embedded\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, top_level_func):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28mself\u001b[39m._func = top_level_func\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minterpolate\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, node_names, graph_debug_info):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from epftoolbox.models import evaluate_dnn_in_test_dataset\n",
        "\n",
        "nlayers = 2\n",
        "shuffle_train = 1\n",
        "data_augmentation = 0\n",
        "calibration_window = 4\n",
        "years_test = 2\n",
        "dataset = 'PJM'\n",
        "experiment_id = 1\n",
        "begin_test_date = None\n",
        "end_test_date = None\n",
        "\n",
        "trials_file_name = (\n",
        "    f'DNN_hyperparameters_nl{nlayers}_dat{dataset}_YT{years_test}'\n",
        "    f\"{'_SF' if shuffle_train else ''}\"\n",
        "    f\"{'_DA' if data_augmentation else ''}\"\n",
        "    f'_CW{calibration_window}_{experiment_id}'\n",
        ")\n",
        "trials_path = work_path / trials_file_name\n",
        "\n",
        "if trials_path.exists():\n",
        "    forecast_dnn = evaluate_dnn_in_test_dataset(\n",
        "        experiment_id=experiment_id,\n",
        "        path_hyperparameter_folder=str(work_path),\n",
        "        path_datasets_folder=str(data_path),\n",
        "        path_recalibration_folder=str(work_path),\n",
        "        nlayers=nlayers,\n",
        "        dataset=dataset,\n",
        "        years_test=years_test,\n",
        "        shuffle_train=bool(shuffle_train),\n",
        "        data_augmentation=bool(data_augmentation),\n",
        "        calibration_window=calibration_window,\n",
        "        new_recalibration=True,\n",
        "        begin_test_date=begin_test_date,\n",
        "        end_test_date=end_test_date,\n",
        "    )\n",
        "    display(forecast_dnn.head())\n",
        "else:\n",
        "    print('Skipping DNN run – hyperparameter trials file not found:')\n",
        "    print(trials_path)\n",
        "    print('Run examples/optimizing_hyperparameters_dnn.py to generate it.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
